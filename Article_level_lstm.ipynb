{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Article level lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MmcM4-MGjlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import dill\n",
        "import pandas as pd\n",
        "import glob, csv\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt') # Download this as this allows you to tokenize words in a string.\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTnOCB818CCp",
        "colab_type": "text"
      },
      "source": [
        "Convert CSV to Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h666elWvGEad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert csv to dataframe\n",
        "train_dataframe = pd.read_csv(\"/content/drive/My Drive/CIS 519/Project/mega_train_70_30.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm6t8LlM4nRL",
        "colab_type": "code",
        "outputId": "765832f9-5e98-4b12-b7d4-cf3517c26c57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7_k48s9HRpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataframe = pd.read_csv(\"/content/drive/My Drive/CIS 519/Project/mega_test_70_30.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPDh-OpwGELf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I4d23s4HgUl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIgA0Cy88Gjp",
        "colab_type": "text"
      },
      "source": [
        " Create new column with author number mappings for ML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwbIawbCcke_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create new col with author number mappings for ML\n",
        "auth_sort = sorted(train_dataframe['Author'].unique())\n",
        "dictOfAuthors = { i : auth_sort[i] for i in range(0, len(auth_sort) ) }\n",
        "swap_dict = {value:key for key, value in dictOfAuthors.items()}\n",
        "train_dataframe['Author_num'] = train_dataframe['Author'].map(swap_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7-GzfXQHm05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create new col with author number mappings for ML\n",
        "auth_sort = sorted(test_dataframe['Author'].unique())\n",
        "dictOfAuthors = { i : auth_sort[i] for i in range(0, len(auth_sort) ) }\n",
        "swap_dict = {value:key for key, value in dictOfAuthors.items()}\n",
        "test_dataframe['Author_num'] = test_dataframe['Author'].map(swap_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVSYPRsbHB5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X84KZnR7Huxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataframe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfNJwXKRHFDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataframe = test_dataframe.drop(columns='Author')\n",
        "train_dataframe = train_dataframe.drop(columns='Author')\n",
        "train_dataframe = train_dataframe.drop(columns='index')\n",
        "test_dataframe = test_dataframe.drop(columns='index')\n",
        "test_dataframe = test_dataframe.drop(columns='hopeful_test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pP2bAPkIINF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_to_choose_train = train_dataframe.text.apply(lambda x : len(x)) > 0 \n",
        "train_df_article = train_dataframe[list_to_choose_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSVRy2XyIX_C",
        "colab_type": "code",
        "outputId": "8f0a9bf3-659d-48c8-daf5-b59fa17439f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "list_to_choose_test = test_dataframe.text.apply(lambda x : len(x)) > 0 \n",
        "test_df_article = test_dataframe[list_to_choose_train]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLzAlOx2Ix7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_article.to_csv(r'/content/drive/My Drive/CIS 519/Project/train_7030.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4ciQcUYNld4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df_article.to_csv(r'/content/drive/My Drive/CIS 519/Project/test_7030.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duHB4Y5MC91q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "TEXT = data.Field(sequential=True, tokenize=\"spacy\", lower=True, include_lengths=True)\n",
        "SCORE = data.Field(sequential=False, use_vocab=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEntQg1R8ORe",
        "colab_type": "text"
      },
      "source": [
        "Utilizing Datafields"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc2fdzmmC9yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datafields = [(\"text\", TEXT),\n",
        "              (\"Author_num\", SCORE)]\n",
        "\n",
        "train= data.TabularDataset(\n",
        "    path='/content/drive/My Drive/CIS 519/Project/train_7030.csv', \n",
        "    format='csv',fields=datafields,skip_header = True)\n",
        "\n",
        "val = data.TabularDataset(\n",
        "    path='/content/drive/My Drive/CIS 519/Project/test_7030.csv', \n",
        "    format='csv',fields=datafields,skip_header = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3Egk-dCC9tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import vocab\n",
        "from torchtext.vocab import GloVe\n",
        "TEXT.build_vocab(train, val, min_freq = 3, vectors=GloVe(name='6B', dim=100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl7olIk58RC4",
        "colab_type": "text"
      },
      "source": [
        "**Iterators**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX9cnPJxC9my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0')\n",
        "BATCH_SIZE = 64\n",
        "train_iterator = data.BucketIterator(\n",
        "    train, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    repeat=False, \n",
        "    shuffle=True,\n",
        "    device = device)\n",
        "\n",
        "val_iterator = data.BucketIterator(\n",
        "    val, \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort=False,\n",
        "    sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch = True,\n",
        "    repeat=False, \n",
        "    shuffle=False,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YOmpexeC9bK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import dill\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_UbebcR8cTU",
        "colab_type": "text"
      },
      "source": [
        "**Network Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWxuWtQhEejS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AuthorClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, mode, output_size, hidden_size, vocab_size, embedding_length, word_embeddings):\n",
        "      super(AuthorClassifier, self).__init__()\n",
        "\n",
        "      if mode not in ['rnn', 'lstm', 'gru', 'bilstm']:\n",
        "        raise ValueError(\"Choose a mode from - rnn / lstm / gru / bilstm\")\n",
        "\n",
        "      self.mode = mode\n",
        "      self.output_size = output_size\n",
        "      self.hidden_size = hidden_size\n",
        "      self.vocab_size = vocab_size\n",
        "      self.embedding_length = embedding_length\n",
        "      self.embedding = nn.Embedding(self.vocab_size,self.embedding_length)\n",
        "      self.embedding.weight = nn.Parameter(word_embeddings,requires_grad = False)\n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "       \n",
        "      if self.mode == 'rnn':\n",
        "        self.network = nn.RNN(self.embedding_length,self.hidden_size)\n",
        "      elif self.mode == 'lstm':\n",
        "        self.network = nn.LSTM(self.embedding_length,self.hidden_size)\n",
        "      elif self.mode == 'gru':\n",
        "        self.network = nn.GRU(self.embedding_length,self.hidden_size)\n",
        "      elif self.mode == 'bilstm':\n",
        "        self.network = nn.LSTM(self.embedding_length,self.hidden_size,bidirectional = True)\n",
        "\n",
        "     \n",
        "      self.fclayer = nn.Linear(self.hidden_size,self.output_size)\n",
        "      \n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "      text_embeddings = self.embedding(text)\n",
        "      pack_sequence = nn.utils.rnn.pack_padded_sequence(text_embeddings,text_lengths)\n",
        "\n",
        "      if self.mode in ('lstm','bilstm'):\n",
        "        a,(hidden,cell) = self.network(pack_sequence)\n",
        "        if self.mode == 'bilstm':\n",
        "          hidden = hidden[0,:,:]+ hidden[1,:,:]\n",
        "      else:\n",
        "        a,hidden = self.network(pack_sequence) \n",
        "      hidden = hidden.squeeze(0)\n",
        "      pred = self.fclayer(hidden)\n",
        "      return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq0xSL0M8kvD",
        "colab_type": "text"
      },
      "source": [
        "**Training and testing models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWY-eX4ZEef8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "def train_classifier(model, dataset_iterator, loss_function, optimizer, num_epochs, log = \"runs\", verbose = False, recurrent = True):\n",
        "  writer = SummaryWriter(log_dir=log)\n",
        "  model.train()\n",
        "  step = 0\n",
        "  f1score_train = []\n",
        "  accuracy_train = []\n",
        "  loss_train = []\n",
        "  for epoch in range(num_epochs):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "    f1 = 0\n",
        "    f1_step = 0\n",
        "    \n",
        "    for batch in dataset_iterator:\n",
        "      comment, comment_lengths = batch.text\n",
        "      labels = batch.Author_num\n",
        "\n",
        "      batch_size = len(labels)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(comment, comment_lengths).squeeze(0)\n",
        "\n",
        "      loss = loss_function(output, labels.long())\n",
        "      loss.backward() \n",
        "      nn.utils.clip_grad_norm(model.parameters(),0.5)\n",
        "      optimizer.step()\n",
        "\n",
        "      pred = torch.max(output.data,1).indices\n",
        "      f1 += sklearn.metrics.f1_score((labels.cpu()).numpy(), (pred.cpu()).numpy(),average= 'macro')\n",
        "      correct += (torch.sum(pred == labels)).item()\n",
        "      total += len(labels)\n",
        "      total_loss += loss.item()\n",
        "      f1_step += 1\n",
        "\n",
        "      if ((step % 100) == 0):\n",
        "        writer.add_scalar(\"Loss/train\", total_loss/total, step)\n",
        "        writer.add_scalar(\"Acc/train\", correct/total, step)\n",
        "        writer.add_scalar(\"F1 Score/train\", f1/f1_step, step)\n",
        "        \n",
        "      step = step+1\n",
        "    f1score_train.append(f1/f1_step)\n",
        "    loss_train.append(total_loss/total)\n",
        "    accuracy_train.append(correct/total)\n",
        "    print('---Training statistics---',\"Epoch: %s Acc: %s Loss: %s\"%(epoch+1, correct/total, total_loss/total),'F1 Score:',f1/f1_step,)\n",
        "\n",
        "  return loss_train,f1score_train,accuracy_train\n",
        "\n",
        "def evaluate_classifier(model, dataset_iterator, loss_function, recurrent = True):\n",
        "  model.eval()\n",
        "\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  total_loss = 0\n",
        "  overall_pred = []\n",
        "  overall_label = []\n",
        "  accuracy_test = []\n",
        "  loss_test = []\n",
        "  f1_step = 0\n",
        "  f1 = 0\n",
        "\n",
        "  for batch in dataset_iterator:\n",
        "    comment, comment_lengths = batch.text\n",
        "    labels = batch.Author_num\n",
        "    output = model(comment, comment_lengths).squeeze(0)\n",
        "    loss = loss_function(output, labels.long())\n",
        "    pred = torch.max(output.data,1).indices \n",
        "    correct += (torch.sum(pred == labels)).item()\n",
        "    total += len(labels)\n",
        "    total_loss += loss.item()\n",
        "    ap = pred.cpu()\n",
        "    a = np.asarray(ap)\n",
        "    labels = labels.cpu()\n",
        "    b = np.asarray(labels)\n",
        "    f1_step += 1\n",
        "    overall_pred.append(a)\n",
        "    overall_label.append(b)\n",
        "\n",
        "  overall_p= [val for sublist in overall_pred for val in sublist]\n",
        "  overall_l = [val for sublist in overall_label for val in sublist]\n",
        "  f1ss = sklearn.metrics.f1_score(overall_l,overall_p,average= 'macro')\n",
        "  accuracy_test.append(correct/total)\n",
        "  loss_test.append(total_loss/total)\n",
        "  print(\"Validation statistics: Acc: %s Loss: %s\"%(correct/total, total_loss/total),'F1 Score:',f1ss)\n",
        "  return overall_pred,overall_label,accuracy_test,f1ss,loss_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKTHJw5x8o4C",
        "colab_type": "text"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVtyn5ZMEec-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LSTM \n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "\n",
        "output_size = 50\n",
        "hidden_size = 300\n",
        "vocab_size = len(TEXT.vocab)\n",
        "embedding_length = 100\n",
        "word_embeddings = TEXT.vocab.vectors\n",
        "num_epochs = 1\n",
        "mode = 'lstm'\n",
        "\n",
        "model = AuthorClassifier(mode, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "log_dir = 'runs/lstm1'\n",
        "final_acc_train_lstm  = []\n",
        "final_loss_train_lstm = []\n",
        "final_loss_test_lstm = []\n",
        "final_acc_test_lstm = []\n",
        "final_f1score_train_lstm = []\n",
        "final_f1score_test_lstm = []\n",
        "\n",
        "\n",
        "for multi in range(20):\n",
        "  loss_train,f1score,accs = train_classifier(model, train_iterator, loss_function, optimizer, log = log_dir, num_epochs = num_epochs)\n",
        "  overall_pred,overall_label,accs_test,f1ss,loss_test = evaluate_classifier(model, val_iterator, loss_function)\n",
        "  final_acc_train_lstm.append(accs[0])\n",
        "  final_acc_test_lstm.append(accs_test[0])\n",
        "  final_f1score_train_lstm.append(f1score[0])\n",
        "  final_f1score_test_lstm.append(f1ss)\n",
        "  final_loss_train_lstm.append(loss_train[0])\n",
        "  final_loss_test_lstm.append(loss_test[0])\n",
        "\n",
        "cf = np.zeros((50,50))\n",
        "\n",
        "overall_pred = [val for sublist in overall_pred for val in sublist]\n",
        "\n",
        "overall_label = [val for sublist in overall_label for val in sublist]\n",
        "\n",
        "ziplist = list(zip(overall_label,overall_pred))\n",
        "for coordinate in ziplist:\n",
        "  cf[coordinate]+=1\n",
        "ax = sns.heatmap(cf,annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Koat6Teg8raP",
        "colab_type": "text"
      },
      "source": [
        "GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uUbdKvcyeLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GRU\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "\n",
        "\n",
        "output_size = 50\n",
        "hidden_size = 300\n",
        "vocab_size = len(TEXT.vocab)\n",
        "embedding_length = 100\n",
        "word_embeddings = TEXT.vocab.vectors\n",
        "num_epochs = 1\n",
        "mode = 'gru'\n",
        "\n",
        "model = AuthorClassifier(mode, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "log_dir = 'runs/gru'\n",
        "final_acc_train_gru  = []\n",
        "final_acc_test_gru = []\n",
        "final_f1score_train_gru = []\n",
        "final_f1score_test_gru = []\n",
        "final_loss_train_gru = []\n",
        "final_loss_test_gru = []\n",
        "\n",
        "for multi in range(20):\n",
        "  loss_train,f1score,accs = train_classifier(model, train_iterator, loss_function, optimizer, log = log_dir, num_epochs = num_epochs)\n",
        "  overall_pred,overall_label,accs_test,f1ss,loss_test = evaluate_classifier(model, val_iterator, loss_function)\n",
        "  final_acc_train_gru.append(accs[0])\n",
        "  final_loss_train_gru.append(loss_train[0])\n",
        "  final_acc_test_gru.append(accs_test[0])\n",
        "  final_f1score_train_gru.append(f1score[0])\n",
        "  final_f1score_test_gru.append(f1ss)\n",
        "  final_loss_test_gru.append(loss_test[0])\n",
        "\n",
        "\n",
        "cf = np.zeros((50,50))\n",
        "\n",
        "overall_pred = [val for sublist in overall_pred for val in sublist]\n",
        "\n",
        "overall_label = [val for sublist in overall_label for val in sublist]\n",
        "\n",
        "ziplist = list(zip(overall_label,overall_pred))\n",
        "for coordinate in ziplist:\n",
        "  cf[coordinate]+=1\n",
        "ax = sns.heatmap(cf,annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7KWH57c8tKE",
        "colab_type": "text"
      },
      "source": [
        "BiLSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7RNoHqC5784",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bilstm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "plt.figure(figsize = (10,10))\n",
        "\n",
        "\n",
        "\n",
        "output_size = 50\n",
        "hidden_size = 300\n",
        "vocab_size = len(TEXT.vocab)\n",
        "embedding_length = 100\n",
        "word_embeddings = TEXT.vocab.vectors\n",
        "num_epochs = 1\n",
        "mode = 'bilstm'\n",
        "\n",
        "model = AuthorClassifier(mode, output_size, hidden_size, vocab_size, embedding_length, word_embeddings)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "log_dir = 'runs/bilstm'\n",
        "final_acc_train_bilstm  = []\n",
        "final_acc_test_bilstm = []\n",
        "final_f1score_train_bilstm = []\n",
        "final_f1score_test_bilstm = []\n",
        "final_loss_train_bilstm = []\n",
        "final_loss_test_bilstm = []\n",
        "\n",
        "for multi in range(20):\n",
        "  loss_train,f1score,accs = train_classifier(model, train_iterator, loss_function, optimizer, log = log_dir, num_epochs = num_epochs)\n",
        "  overall_pred,overall_label,accs_test,f1ss,loss_test = evaluate_classifier(model, val_iterator, loss_function)\n",
        "  final_acc_train_bilstm.append(accs[0])\n",
        "  final_loss_train_bilstm.append(loss_train[0])\n",
        "  final_acc_test_bilstm.append(accs_test[0])\n",
        "  final_f1score_train_bilstm.append(f1score[0])\n",
        "  final_f1score_test_bilstm.append(f1ss)\n",
        "  final_loss_test_bilstm.append(loss_test[0])\n",
        "\n",
        "\n",
        "cf = np.zeros((50,50))\n",
        "\n",
        "overall_pred = [val for sublist in overall_pred for val in sublist]\n",
        "\n",
        "overall_label = [val for sublist in overall_label for val in sublist]\n",
        "\n",
        "ziplist = list(zip(overall_label,overall_pred))\n",
        "for coordinate in ziplist:\n",
        "  cf[coordinate]+=1\n",
        "ax = sns.heatmap(cf,annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kR2Epg98xMl",
        "colab_type": "text"
      },
      "source": [
        "Plot - Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LVYNRup6-Yl",
        "colab_type": "code",
        "outputId": "7b405481-b7e4-462f-fbe9-f5267dd8eeea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "#Plot - accuracy\n",
        "import plotly.graph_objects as go\n",
        "fig_accuracy = go.Figure()\n",
        "\n",
        "fig_accuracy.add_trace(go.Scatter(\n",
        "    y=final_acc_train_lstm,\n",
        "    connectgaps=True, marker_color='rgba(128, 0, 0, 0.9)', name = 'Training accuracy lstm'))\n",
        "\n",
        "fig_accuracy.add_trace(go.Scatter(\n",
        "    y=final_acc_test_lstm,\n",
        "    connectgaps=True, marker_color='rgba(255, 0, 0, 0.9)', name = 'Testing accuracy lstm'))\n",
        "\n",
        "fig_accuracy.add_trace(go.Scatter(\n",
        "    y=final_acc_train_gru,\n",
        "    connectgaps=True, marker_color='rgba(0, 128, 0, 0.9)', name = 'Training accuracy gru'))\n",
        "fig_accuracy.add_trace(go.Scatter(\n",
        "    y=final_acc_test_gru,\n",
        "    connectgaps=True, marker_color = 'rgba(0, 255, 0, 0.9)', name = 'Testing accuracy gru'))\n",
        "\n",
        "fig_accuracy.add_trace(go.Scatter(\n",
        "    y=final_acc_train_bilstm,\n",
        "    connectgaps=True, marker_color='rgba(0, 0, 128, 0.9)', name = 'Training accuracy bilstm'))\n",
        "fig_accuracy.add_trace(go.Scatter(\n",
        "    y=final_acc_test_bilstm, connectgaps=True, marker_color='rgba(0, 0, 255, 0.9)',\n",
        "    name='Test accuracy bilstm'))\n",
        "\n",
        "fig_accuracy.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"8a6aff39-8d27-48a2-bcb8-02d3075dd8be\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"8a6aff39-8d27-48a2-bcb8-02d3075dd8be\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '8a6aff39-8d27-48a2-bcb8-02d3075dd8be',\n",
              "                        [{\"connectgaps\": true, \"marker\": {\"color\": \"rgba(128, 0, 0, 0.9)\"}, \"name\": \"Training accuracy lstm\", \"type\": \"scatter\", \"y\": [0.14057142857142857, 0.2642857142857143, 0.342, 0.43942857142857145, 0.5131428571428571, 0.5691428571428572, 0.6228571428571429, 0.6817142857142857, 0.7534285714285714, 0.7982857142857143, 0.8382857142857143, 0.88, 0.906, 0.9225714285714286, 0.94, 0.9522857142857143, 0.966, 0.9731428571428572, 0.9788571428571429, 0.9777142857142858]}, {\"connectgaps\": true, \"marker\": {\"color\": \"rgba(255, 0, 0, 0.9)\"}, \"name\": \"Testing accuracy lstm\", \"type\": \"scatter\", \"y\": [0.22333333333333333, 0.2986666666666667, 0.36533333333333334, 0.45066666666666666, 0.5013333333333333, 0.5233333333333333, 0.5466666666666666, 0.5766666666666667, 0.6073333333333333, 0.62, 0.6253333333333333, 0.6093333333333333, 0.6313333333333333, 0.6406666666666667, 0.646, 0.6586666666666666, 0.6686666666666666, 0.654, 0.6613333333333333, 0.6513333333333333]}, {\"connectgaps\": true, \"marker\": {\"color\": \"rgba(0, 128, 0, 0.9)\"}, \"name\": \"Training accuracy gru\", \"type\": \"scatter\", \"y\": [0.196, 0.47828571428571426, 0.6694285714285715, 0.79, 0.868, 0.9137142857142857, 0.9217142857142857, 0.9377142857142857, 0.9405714285714286, 0.9174285714285715, 0.8934285714285715, 0.8234285714285714, 0.7794285714285715, 0.5674285714285714, 0.648, 0.7102857142857143, 0.594, 0.612, 0.6042857142857143, 0.6125714285714285]}, {\"connectgaps\": true, \"marker\": {\"color\": \"rgba(0, 255, 0, 0.9)\"}, \"name\": \"Testing accuracy gru\", \"type\": \"scatter\", \"y\": [0.37466666666666665, 0.56, 0.6553333333333333, 0.6786666666666666, 0.7173333333333334, 0.708, 0.7173333333333334, 0.7293333333333333, 0.7013333333333334, 0.6733333333333333, 0.6226666666666667, 0.654, 0.5013333333333333, 0.46, 0.5866666666666667, 0.5246666666666666, 0.49133333333333334, 0.5073333333333333, 0.48733333333333334, 0.55]}, {\"connectgaps\": true, \"marker\": {\"color\": \"rgba(0, 0, 128, 0.9)\"}, \"name\": \"Training accuracy bilstm\", \"type\": \"scatter\", \"y\": [0.2837142857142857, 0.508, 0.6474285714285715, 0.744, 0.8182857142857143, 0.8594285714285714, 0.8988571428571429, 0.9285714285714286, 0.9617142857142857, 0.9711428571428572, 0.974, 0.986, 0.9891428571428571, 0.9928571428571429, 0.9925714285714285, 0.9974285714285714, 0.9994285714285714, 1.0, 1.0, 1.0]}, {\"connectgaps\": true, \"marker\": {\"color\": \"rgba(0, 0, 255, 0.9)\"}, \"name\": \"Test accuracy bilstm\", \"type\": \"scatter\", \"y\": [0.44066666666666665, 0.5533333333333333, 0.6126666666666667, 0.6413333333333333, 0.6546666666666666, 0.6726666666666666, 0.668, 0.696, 0.6906666666666667, 0.7093333333333334, 0.688, 0.7013333333333334, 0.6966666666666667, 0.7013333333333334, 0.6906666666666667, 0.692, 0.7013333333333334, 0.7066666666666667, 0.7086666666666667, 0.71]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8a6aff39-8d27-48a2-bcb8-02d3075dd8be');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGtC1zlW8z5O",
        "colab_type": "text"
      },
      "source": [
        "Loss Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brpLqdhb7o30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loss Plots\n",
        "import plotly.graph_objects as go\n",
        "fig_loss = go.Figure()\n",
        "\n",
        "fig_loss.add_trace(go.Scatter(\n",
        "    y=final_loss_train_lstm,\n",
        "    connectgaps=True, marker_color='rgba(128, 0, 0, 0.9)', name = 'Training Loss lstm'))\n",
        "\n",
        "fig_loss.add_trace(go.Scatter(\n",
        "    y=final_loss_test_lstm,\n",
        "    connectgaps=True, marker_color='rgba(255, 0, 0, 0.9)', name = 'Testing Loss lstm'))\n",
        "\n",
        "fig_loss.add_trace(go.Scatter(\n",
        "    y=final_loss_train_gru,\n",
        "    connectgaps=True, marker_color='rgba(0, 128, 0, 0.9)', name = 'Training Loss gru'))\n",
        "\n",
        "fig_loss.add_trace(go.Scatter(\n",
        "    y=final_loss_test_gru,\n",
        "    connectgaps=True, marker_color='rgba(0, 255, 0, 0.9)', name = 'Testing Loss gru'))\n",
        "\n",
        "fig_loss.add_trace(go.Scatter(\n",
        "    y=final_loss_train_bilstm,\n",
        "    connectgaps=True, marker_color='rgba(0, 0, 128, 0.9)', name = 'Training Loss bilstm'))\n",
        "\n",
        "fig_loss.add_trace(go.Scatter(\n",
        "    y=final_loss_test_bilstm,\n",
        "    connectgaps=True, marker_color='rgba(0, 0, 255, 0.9)', name = 'Testing Loss bilstm'))\n",
        "\n",
        "fig_loss.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaXVezQ-82LJ",
        "colab_type": "text"
      },
      "source": [
        "F1 Score plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcH_jSJuKGID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot - f1score\n",
        "import plotly.graph_objects as go\n",
        "fig_f1score = go.Figure()\n",
        "\n",
        "fig_f1score.add_trace(go.Scatter(\n",
        "    y=final_f1score_train_lstm,\n",
        "    connectgaps=True, marker_color='rgba(128, 0, 0, 0.9)', name = 'Training f1score lstm'))\n",
        "\n",
        "fig_f1score.add_trace(go.Scatter(\n",
        "    y=final_f1score_test_lstm,\n",
        "    connectgaps=True, marker_color='rgba(255, 0, 0, 0.9)', name = 'Testing f1score lstm'))\n",
        "\n",
        "fig_f1score.add_trace(go.Scatter(\n",
        "    y=final_f1score_train_gru,\n",
        "    connectgaps=True, marker_color='rgba(0, 128, 0, 0.9)', name = 'Training f1score gru'))\n",
        "fig_f1score.add_trace(go.Scatter(\n",
        "    y=final_f1score_test_gru,\n",
        "    connectgaps=True, marker_color = 'rgba(0, 255, 0, 0.9)', name = 'Testing f1score gru'))\n",
        "\n",
        "fig_f1score.add_trace(go.Scatter(\n",
        "    y=final_f1score_train_bilstm,\n",
        "    connectgaps=True, marker_color='rgba(0, 0, 128, 0.9)', name = 'Training f1score bilstm'))\n",
        "fig_f1score.add_trace(go.Scatter(\n",
        "    y=final_f1score_test_bilstm, connectgaps=True, marker_color='rgba(0, 0, 255, 0.9)',\n",
        "    name='Test f1score bilstm'))\n",
        "\n",
        "fig_f1score.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5fBMd-XhcA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}